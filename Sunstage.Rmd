---
title: "Sunday_test"
author: "JR Sanders"
date: "October 22, 2017"
output: html_document
---
---
title: "Machine Learning For Exercise Routine"
author: "Sredans-JR"
date: "October 20, 2017"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_current$set
(echo = FALSE)
```
##  Background
To be able to predict the weight lifting routine of twenty cases. The data was gathered from accelerometers. Using devices such as Jawbone Up,and Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These types of devices are part of the quantified self movement a group of enthusiasts who take measurements about themselves regularly to improve their health,to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do but they rarely quantify how well they do it. In this project, the goal is to use data from accelerometers on the belt, forearm, arm and dumbell of six participants. They were asked to perform barbell lifts correctly and incorrectly in five different ways.   
```{r, warning = FALSE , echo = TRUE}
Sys.info()
Sys.time()
```
## Loading required libraries and datasets
```{r}
setwd("C:/Users/jehuti1/Documents/2017_MachineLearning/projectml")
library(caret , quietly = TRUE )
library(randomForest , quietly = TRUE)
library(psych, quietly = TRUE)
library(corrplot, quietly = TRUE)
traindsetq10 <- read.csv("pml-training.csv")
testdsetq10 <- read.csv("pml-testing.csv")
```
### Assessing the predictor columns NA count and removing extraneous columns 
1. For examples timestamps, usernames and columns/features that are not populated significantly, less than 50%,  with data. 
2. Removed seven columns that do not contain sensor measurements.

```{r, warning= FALSE }
colcount = ncol(traindsetq10)
rowcount = nrow(traindsetq10)
na = integer()
for (i in 1:colcount) {
# Add the amount of na's  in the column
# If it is more than half of the total number of columns remove it  

  fraction = sum(is.na(traindsetq10[,i])) / rowcount
           if (fraction > 0.5) {
             na = c(na,i)
           }
}

traindsetq10 = traindsetq10[,-c(na)]
foremovable <- grepl("kurtosis|skewness|X|yaw|user_name|new_window|timestamp",colnames(traindsetq10))
traindsetq10 <-  traindsetq10[,!foremovable]
traindsetq10shorten <- data.frame()
traindsetq10shorten <- traindsetq10
colnames(traindsetq10shorten)

```
### Partition data set to create a data set and validation set
```{r, warning = FALSE}
ptrain = createDataPartition(y = traindsetq10shorten$classe, p = 0.7, 
                             list = FALSE)
usefortrain = traindsetq10shorten[ptrain,]
useforvalid = traindsetq10shorten[-ptrain,]
```

### Correlation Matrix 
1. To explore the association between the predictors
2. To explore the possiblities of uncorrelated data
3. To confirm the use of principal component analysis
```{r}
corMatts <- cor(usefortrain[, -50])
corrplot(corMatts,order = "FPC", method = "color" , type = "lower", tl.cex = 0.8, tl.col = rgb(0,0,0))
```

###  Scree Plots - Training Dataset Scree Plot 
#### Last point of inflection at 30 components for both scree plots
#### Used to determine how many components should be selected for the modeling stage
```{r, warning = FALSE}
# Correlation Plot

####### Training D Set Scree Plot
preProc351 <- preProcess(usefortrain[,-50], method = "pca", pcaComp = 35 )
trainpc <- predict(preProc351, usefortrain[, -50])
pca11 <- principal(trainpc, nfactors = 35, rotate = "none") 
plot(pca11$values, type = "b", ylab = "Eigenvalues" , xlab = "Component"  )
```

### Validation Dataset Scree Plot
#### Used to suggest how many components could be selected for the modeling stage
```{r}
####### Validation Set Scree Plot
preProc351val <- preProcess(useforvalid[,-50], method = "pca", pcaComp = 35 )
trainpcv <- predict(preProc351val, useforvalid[, -50])
pcaval <- principal(trainpcv, nfactors = 35, rotate = "none") 
plot(pcaval$values, type = "b", ylab = "Eigenvalues" , xlab = "Component"  )
#############################
############# TRAINING OF MODEL
```
### Predictive Model Train Control 
4-fold cross validation was employed.

### Applying Model To The Testing Dataset
#### Results
###### The twenty predictions are not shown
1. Prediction error rate as meassured by out-of-bag error 2.34%
2. Two variables were tried at each split, mtry = 2
 
```{r, warning = FALSE}
tcontrol <- trainControl(method = "cv" , number = 4)
```
### Pricipal Component of UnCorrelated Data 
#####  Y-axis sorts components in decreasing order of importance
#####  Listed first, at the max location of the y-axis, is the most important component

## Confusion Matrix Generated for Train Dataset & Validation Data
1. Accuracy 99.31% for Training dataset
2. Accuracy 97.71% for Validation dataset
3. Both p-values were less than 2.2e-16
